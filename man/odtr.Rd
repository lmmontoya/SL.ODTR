% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/4odtr.R
\name{odtr}
\alias{odtr}
\title{Function that computes ODTR}
\usage{
odtr(
  W,
  A,
  Y,
  V,
  rule.output = "d",
  g.SL.library,
  QAW.SL.library,
  blip.SL.library,
  dopt.SL.library = NULL,
  risk.type,
  metalearner,
  kappa = NULL,
  newV = NULL,
  QAW.fun = NULL,
  VFolds = 10,
  grid.size = 100,
  family = NULL,
  ab = NULL,
  cs_to_try = NULL,
  alphas_to_try = NULL
)
}
\arguments{
\item{W}{Data frame of observed baseline covariates}

\item{A}{Vector of treatment}

\item{Y}{Vector of treatment (continuous or binary)}

\item{V}{Data frame of observed baseline covariates (subset of W) used to design the ODTR}

\item{rule.output}{Either "d" for deterministic ODTR or "g" for stochastic ODTR or "rc" for (stochastic) resource-constrained ODTR. Default is "d."}

\item{g.SL.library}{Character vector for logistic regression modeling the treatment mechanism. Default is 1 (i.e., using mean of A as estimate of g1W).}

\item{QAW.SL.library}{SuperLearner library for estimating the outcome regression}

\item{blip.SL.library}{SuperLearner library for estimating blip}

\item{dopt.SL.library}{SuperLearner library for estimating dopt directly. Default is \code{NULL}. Could be "DonV", "Qlearn", "OWL", "EARL", "optclass", "RWL", "treatall", "treatnone". Could also be "all" for all algorithms.}

\item{risk.type}{Risk type in order to pick optimal combination of coefficients to combine the candidate algorithms. For (1) MSE risk use "CV MSE"; for (2) -E[Ydopt] risk use "CV IPCWDR" (for -E[Ydopt] estimated using double-robust IPTW) or "CV TMLE" (for -E[Ydopt] estimates using TMLE); (3) For the upper bound of the CI of -E[Ydopt] use "CV TMLE CI"}

\item{metalearner}{Discrete ("discrete"), blip-based ("blip"), vote-based SuperLearner ("vote"). Note that if metalearner is "vote" then cannot put in resource constraints (kappa).}

\item{kappa}{For ODTR with resource constraints, kappa is the proportion of people in the population who are allowed to receive treatment. Default is \code{NULL}.}

\item{newV}{New V for prediction}

\item{QAW.fun}{True outcome regression E[Y|A,W]. Useful for simulations. Default is \code{NULL}.}

\item{VFolds}{Number of folds to use in cross-validation. Default is 10.}

\item{grid.size}{Grid size for \code{\link[hitandrun:simplex.sample]{simplex.sample()}} function to create possible combinations of coefficients}

\item{family}{Either "gaussian" or "binomial". Default is null, if outcome is between 0 and 1 it will change to binomial, otherwise gaussian}

\item{ab}{Range of Y}

\item{cs_to_try}{Constants for SL.blip.c}

\item{alphas_to_try}{Convex combination alphas for SL.blip.alpha}
}
\value{
odtr object
}
\description{
Given a W, A, Y dataset, this function will compute the estimated ODTR using SuperLearner. If a QAW function is provided that computes the true E[Y|A,W] (e.g., if simulating), the function will also return the true treatment under the optimal rule and other metrics of evaluating the estimated optimal rule's performance.
}
\examples{
## Example
library(SuperLearner)
library(hitandrun)
ObsData = subset(DGP_bin_simple(1000), select = -c(A_star, Y_star))
W = subset(ObsData, select = -c(A,Y))
V = W
A = ObsData$A
Y = ObsData$Y

# blip-based estimate of ODTR with risk function CV-TMLE
odtr(W = W, gform = "W1 + W2", A = A, Y = Y, V = W, blip.SL.library = "SL.blip.HTEepi", QAW.SL.library = "SL.QAW.HTEepi", risk.type = "CV TMLE", metalearner = 'blip')


}
\references{
Luedtke, Alexander R., and Mark J. van der Laan. "Super-learning of an optimal dynamic treatment rule." \emph{The international journal of biostatistics} 12.1 (2016): 305-332.
Coyle, J.R. (2017). Jeremy Coyle, “Computational Considerations for Targeted Learning” PhD diss., University of California, Berkeley 2017 \url{https://escholarship.org/uc/item/9kh0b9vm}.
Eric Polley, Erin LeDell, Chris Kennedy and Mark van der Laan (2018). SuperLearner: Super Learner Prediction. R package version 2.0-24. \url{https://CRAN.R-project.org/package=SuperLearner}.
}
