% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/5EYdopt.R
\name{EYdopt}
\alias{EYdopt}
\title{Estimation of E[Ydopt]}
\usage{
EYdopt(W, W_for_g = 1, V, A, Y, SL.type, QAW.SL.library, blip.SL.library,
  dopt.SL.library = NULL, risk.type, moMain_model = NULL,
  moCont_model = NULL, grid.size = 100, VFolds = 10, kappa = NULL,
  QAW = NULL, g1W = NULL, family = NULL)
}
\arguments{
\item{W}{Data frame of observed baseline covariates}

\item{W_for_g}{Data frame of observed baseline covariates used for predicting g1W (probability of treatment) via a GLM, e.g., if there's stratified randomization.}

\item{V}{Data frame of observed baseline covariates (subset of W) used to design the ODTR}

\item{A}{Vector of treatment}

\item{Y}{Vector of outcome (continuous or binary)}

\item{SL.type}{Blip-based ("blip") or vote-based SuperLearner ("vote"). Note that if SL.type is "vote" then cannot put in kappa.}

\item{QAW.SL.library}{SuperLearner library for estimating outcome regression}

\item{blip.SL.library}{SuperLearner library for estimating the blip}

\item{dopt.SL.library}{SuperLearner library for estimating dopt directly. Default is \code{NULL}.}

\item{risk.type}{Risk type in order to pick optimal combination of coefficients to combine the candidate algorithms. For (1) MSE risk use "CV MSE" and for (2) E[Ydopt] risk use "CV IPCWDR" (for E[Ydopt] estimated using double-robust IPTW) or "CV TMLE" (for E[Ydopt] estimates using TMLE)}

\item{moMain_model}{for DynTxRegime outcome regression}

\item{moCont_model}{for DynTxRegime contrast function}

\item{grid.size}{Grid size for \code{\link[hitandrun:simplex.sample]{simplex.sample()}} function to create possible combinations of coefficients}

\item{VFolds}{Number of folds to use in cross-validation. Default is 10.}

\item{kappa}{For ODTR with resource constriants, kappa is the proportion of people in the population who are allowed to receive treatment. Default is \code{NULL}.}

\item{QAW}{True outcome regression E[Y|A,W]. Useful for simulations. Default is \code{NULL}.}

\item{g1W}{user-supplied vector of g1W}

\item{family}{either "gaussian" or "binomial". Default is null, if outcome is between 0 and 1 it will change to binomial, otherwise gaussian}

\item{QAW}{True outcome regression E[Y|A,W]. Useful for simulations. Default is \code{NULL}.}
}
\value{
If the true Qbar function is specified, the output will be a vector of point estimates of E[Ydopt] and their respective confidence intervals. This will be for both the estimated optimal rule and the true optimal rule. Performance results on the optimal rule will also be output: proportion of people treated under ODTR, proportion of times the estimated rule matches the optimal rule, the mean outcome under the estimated optimal rule under the true mean outcome function, and the mean outcome under the estimated optimal rule under the sample-specific true mean outcome.

If the true Qbar is not specified, return:
\describe{
  \item{EYdopt_estimates}{Point estimates and confidence intervals for E[Ydopt], using the unadjusted mean outcome for the people who received the optimal rule, g-computation, IPTW, IPTW-DR, TMLE}
  \item{SL.odtr}{SuperLearner list. See \code{SL.blip} or \code{SL.vote} documentation.}
}
}
\description{
Given a W, A, Y dataset, this function will compute the estimated ODTR using SuperLearner. If a Qbar function is provided that computes the true E[Y|A,W] (e.g., if simulating), the function will also return the true treatment under the optimal rule and other metrics of evaluating the estimated optimal rule's performance. Then, it will estimate E[Ydopt] using g-computation, IPTW, IPTW-DR, TMLE, and CV-TMLE. Follows the framework of Luedtke and van der laan, 2015 and 2016.
}
\examples{
## Example
library(SuperLearner)
library(hitandrun)
ObsData = subset(DGP_smooth2(1000), select = -c(A_star, Y_star))
W = subset(ObsData, select = -c(A,Y))
V = W
A = ObsData$A
Y = ObsData$Y

# E[Ydopt] using blip-based estimate of ODTR with risk function CV-TMLE
EYdopt(W = W, A = A, Y = Y, V = W, blip.SL.library = "SL.blip.correct_smooth", QAW.SL.library = "SL.QAW.correct_smooth", risk.type = "CV TMLE", SL.type = 'blip')
}
\references{
van der Laan, Mark J., and Alexander R. Luedtke. "Targeted learning of the mean outcome under an optimal dynamic treatment rule." \emph{Journal of causal inference} 3.1 (2015): 61-95.

Luedtke, Alexander R., and Mark J. van der Laan. "Super-learning of an optimal dynamic treatment rule." \emph{The international journal of biostatistics} 12.1 (2016): 305-332.

Luedtke, Alexander R., and Mark J. van der Laan. "Optimal individualized treatments in resource-limited settings." \emph{The international journal of biostatistics} 12.1 (2016): 283-303.

Coyle, J.R. (2017). Jeremy Coyle, “Computational Considerations for Targeted Learning” PhD diss., University of California, Berkeley 2017 \url{https://escholarship.org/uc/item/9kh0b9vm}.
}
